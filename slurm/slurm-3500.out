The activation script must be sourced, otherwise the virtual environment will not work.
Setting vars
[32m[I 2023-07-14 08:34:32,066][0m A new study created in memory with name: no-name-5f9fd102-82bb-4502-9ff6-598d29685758[0m
[[36m2023-07-14 08:34:32,066[0m][[35mHYDRA[0m] Study name: no-name-5f9fd102-82bb-4502-9ff6-598d29685758[0m
[[36m2023-07-14 08:34:32,066[0m][[35mHYDRA[0m] Storage: None[0m
[[36m2023-07-14 08:34:32,066[0m][[35mHYDRA[0m] Sampler: TPESampler[0m
[[36m2023-07-14 08:34:32,067[0m][[35mHYDRA[0m] Directions: ['minimize'][0m
[[36m2023-07-14 08:34:32,075[0m][[35mHYDRA[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 6 jobs[0m
[[36m2023-07-14 08:34:32,075[0m][[35mHYDRA[0m] Launching jobs, sweep output dir : /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#0 : model.optimizer.lr=0.01923279309285134 data.batch_size=128 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#1 : model.optimizer.lr=0.027332001267735898 data.batch_size=128 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#2 : model.optimizer.lr=0.03584594526879088 data.batch_size=128 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#3 : model.optimizer.lr=0.05616349898795594 data.batch_size=256 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#4 : model.optimizer.lr=0.0365521097917471 data.batch_size=256 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:32,076[0m][[35mHYDRA[0m] 	#5 : model.optimizer.lr=0.06517267650833508 data.batch_size=64 experiment=stars_experiment.yaml trainer=gpu logger=tensorboard hparams_search=stars_optuna.yaml[0m
[[36m2023-07-14 08:34:44,736[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 08:34:44,744[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 128                                                         
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.03584594526879088                                               
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
[[36m2023-07-14 08:34:44,785[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 08:34:44,786[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 08:34:44,793[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-14 08:34:44,794[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 08:34:44,794[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-14 08:34:44,796[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[rank: 0] Global seed set to 12345
[[36m2023-07-14 08:34:44,803[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-14 08:34:44,804[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-14 08:34:44,822[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 08:34:44,835[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 08:34:44,847[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 64                                                          
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.06517267650833508                                               
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 256                                                         
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.0365521097917471                                                
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 128                                                         
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.027332001267735898                                              
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 128                                                         
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.01923279309285134                                               
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
[rank: 0] Global seed set to 12345
[rank: 0] Global seed set to 12345
[rank: 0] Global seed set to 12345
[rank: 0] Global seed set to 12345
CONFIG
├── data
│   └── _target_: src.data.stars_datamodule.StarsDataModule                     
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       batch_size: 256                                                         
│       train_val_test_split:                                                   
│       - 0.7                                                                   
│       - 0.1                                                                   
│       - 0.2                                                                   
│       num_workers: 0                                                          
│       pin_memory: false                                                       
│                                                                               
├── model
│   └── _target_: src.models.stars_module.StarsLitModule                        
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.05616349898795594                                               
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       net:                                                                    
│         _target_: src.models.components.multilayer_perceptron.MLP             
│         input_size: 4302                                                      
│         lin1_size: 2048                                                       
│         lin2_size: 1024                                                       
│         lin3_size: 512                                                        
│         lin4_size: 256                                                        
│         lin5_size: 64                                                         
│         lin6_size: 32                                                         
│         output_size: 4                                                        
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multir
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mae                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 1                                                         
│         mode: min                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/mae                                                      
│         min_delta: 0.0                                                        
│         patience: 100                                                         
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── tensorboard:                                                            
│         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
│         save_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│         name: stars                                                           
│         log_graph: false                                                      
│         default_hp_metric: true                                               
│         prefix: ''                                                            
│       aim:                                                                    
│         experiment: stars                                                     
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train
│       min_epochs: 100                                                         
│       max_epochs: 400                                                         
│       accelerator: gpu                                                        
│       devices: 1                                                              
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│                                                                               
├── paths
│   └── root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
│       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
│       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
│       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multi
│       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── tags
│   └── ['stars', 'mlp']                                                        
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── compile
│   └── False                                                                   
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── optimized_metric
    └── val/mae_best                                                            
[[36m2023-07-14 08:34:44,892[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 08:34:44,894[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 08:34:44,902[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 08:34:44,902[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[rank: 0] Global seed set to 12345
[[36m2023-07-14 08:34:44,915[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 08:34:46,091[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,092[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,092[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,092[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,093[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,093[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 08:34:46,193[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,193[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,198[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,199[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,200[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,204[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,204[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,206[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2023-07-14 08:34:46,207[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,208[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,211[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,212[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,213[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,213[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,214[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,215[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2023-07-14 08:34:46,230[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,231[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,236[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,237[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,237[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,237[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,238[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,239[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,239[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,239[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,240[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2023-07-14 08:34:46,240[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,240[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2023-07-14 08:34:46,241[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2023-07-14 08:34:46,242[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,243[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,244[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,245[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,245[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2023-07-14 08:34:46,245[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,245[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,246[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,246[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2023-07-14 08:34:46,246[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,247[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2023-07-14 08:34:46,247[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,247[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 08:34:46,247[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2023-07-14 08:34:46,247[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,248[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2023-07-14 08:34:46,250[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2023-07-14 08:34:46,250[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,202[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,229[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,337[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,352[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,358[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 08:34:47,365[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2023-07-14 08:34:47,549[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
[[36m2023-07-14 08:34:47,550[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
[[36m2023-07-14 08:34:47,550[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
[[36m2023-07-14 08:34:47,555[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
[[36m2023-07-14 08:34:47,559[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
[[36m2023-07-14 08:34:47,566[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
SLURM auto-requeueing enabled. Setting signal handlers.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
SLURM auto-requeueing enabled. Setting signal handlers.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
SLURM auto-requeueing enabled. Setting signal handlers.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
┏━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name         ┃ Type              ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net          │ MLP               │ 11.6 M │
│ 1  │ net.model    │ Sequential        │ 11.6 M │
│ 2  │ net.model.0  │ Linear            │  8.8 M │
│ 3  │ net.model.1  │ BatchNorm1d       │  4.1 K │
│ 4  │ net.model.2  │ ReLU              │      0 │
│ 5  │ net.model.3  │ Linear            │  2.1 M │
│ 6  │ net.model.4  │ BatchNorm1d       │  2.0 K │
│ 7  │ net.model.5  │ ReLU              │      0 │
│ 8  │ net.model.6  │ Linear            │  524 K │
│ 9  │ net.model.7  │ BatchNorm1d       │  1.0 K │
│ 10 │ net.model.8  │ ReLU              │      0 │
│ 11 │ net.model.9  │ Linear            │  131 K │
│ 12 │ net.model.10 │ BatchNorm1d       │    512 │
│ 13 │ net.model.11 │ ReLU              │      0 │
│ 14 │ net.model.12 │ Linear            │ 16.4 K │
│ 15 │ net.model.13 │ BatchNorm1d       │    128 │
│ 16 │ net.model.14 │ ReLU              │      0 │
│ 17 │ net.model.15 │ Linear            │  2.1 K │
│ 18 │ net.model.16 │ BatchNorm1d       │     64 │
│ 19 │ net.model.17 │ ReLU              │      0 │
│ 20 │ net.model.18 │ Linear            │    132 │
│ 21 │ criterion    │ MSELoss           │      0 │
│ 22 │ train_mae    │ MeanAbsoluteError │      0 │
│ 23 │ val_mae      │ MeanAbsoluteError │      0 │
│ 24 │ test_mae     │ MeanAbsoluteError │      0 │
│ 25 │ train_loss   │ MeanMetric        │      0 │
│ 26 │ val_loss     │ MeanMetric        │      0 │
│ 27 │ test_loss    │ MeanMetric        │      0 │
│ 28 │ val_mae_best │ MinMetric         │      0 │
└────┴──────────────┴───────────────────┴────────┘
Trainable params: 11.6 M                                                        
Non-trainable params: 0                                                         
Total params: 11.6 M                                                            
Total estimated model params size (MB): 46                                      
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
Epoch 159/399 ━━━━━━━━━━━━━━━ 72/72 0:00:00 •       130.10it/s v_num: 0         
                                    0:00:00                    val/loss: 0.056  
                                                               val/mae: 0.16    
                                                               val/mae_best:    
                                                               0.151 train/loss:
                                                               0.02 train/mae:  
                                                               0.098            
[[36m2023-07-14 08:56:05,712[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/5/checkpoints/epoch_059.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/5/checkpoints/epoch_059.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.046579599380493164    │
│         test/mae          │    0.14421820640563965    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21/21 0:00:00 • 0:00:00 358.87it/s 
[[36m2023-07-14 08:56:06,503[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/5/checkpoints/epoch_059.ckpt[0m
[[36m2023-07-14 08:56:06,505[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/5[0m
[[36m2023-07-14 08:56:06,671[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.15103943645954132>[0m
Epoch 190/399 ━━━━━━━━━━━━━━━ 36/36 0:00:00 •       104.17it/s v_num: 0         
                                    0:00:00                    val/loss: 0.042  
                                                               val/mae: 0.129   
                                                               val/mae_best:    
                                                               0.107 train/loss:
                                                               0.015 train/mae: 
                                                               0.081            
[[36m2023-07-14 08:59:35,782[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/1/checkpoints/epoch_090.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/1/checkpoints/epoch_090.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.028541410341858864    │
│         test/mae          │    0.09943097084760666    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11/11 0:00:00 • 0:00:00 245.31it/s 
[[36m2023-07-14 08:59:36,574[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/1/checkpoints/epoch_090.ckpt[0m
[[36m2023-07-14 08:59:36,576[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/1[0m
[[36m2023-07-14 08:59:36,705[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.10665453970432281>[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 225/399 ━━━━━━━━━━━━━━━ 18/18 0:00:00 •       139.82it/s v_num: 0         
                                    0:00:00                    val/loss: 0.03   
                                                               val/mae: 0.102   
                                                               val/mae_best:    
                                                               0.096 train/loss:
                                                               0.015 train/mae: 
                                                               0.08             
[[36m2023-07-14 09:02:37,816[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/3/checkpoints/epoch_125.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/3/checkpoints/epoch_125.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.027474259957671165    │
│         test/mae          │    0.09125321358442307    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 253.04it/s 
[[36m2023-07-14 09:02:38,488[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/3/checkpoints/epoch_125.ckpt[0m
[[36m2023-07-14 09:02:38,489[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/3[0m
[[36m2023-07-14 09:02:38,497[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.0957183837890625>[0m
Epoch 230/399 ━━━━━━━━━━━━━━━ 36/36 0:00:00 •       132.26it/s v_num: 0         
                                    0:00:00                    val/loss: 0.042  
                                                               val/mae: 0.126   
                                                               val/mae_best:    
                                                               0.111 train/loss:
                                                               0.017 train/mae: 
                                                               0.085            
[[36m2023-07-14 09:02:46,393[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/2/checkpoints/epoch_130.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/2/checkpoints/epoch_130.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.031348008662462234    │
│         test/mae          │    0.10458698868751526    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11/11 0:00:00 • 0:00:00 350.80it/s 
[[36m2023-07-14 09:02:46,638[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/2/checkpoints/epoch_130.ckpt[0m
[[36m2023-07-14 09:02:46,640[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/2[0m
[[36m2023-07-14 09:02:46,647[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.11062765121459961>[0m
Epoch 230/399 ━━━━━━━━━━━━━━━ 36/36 0:00:00 •       161.69it/s v_num: 0         
                                    0:00:00                    val/loss: 0.039  
                                                               val/mae: 0.123   
                                                               val/mae_best:    
                                                               0.107 train/loss:
                                                               0.015 train/mae: 
                                                               0.08             
[[36m2023-07-14 09:02:51,860[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/0/checkpoints/epoch_130.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/0/checkpoints/epoch_130.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.029255645349621773    │
│         test/mae          │    0.10097485035657883    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11/11 0:00:00 • 0:00:00 364.11it/s 
[[36m2023-07-14 09:02:52,104[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/0/checkpoints/epoch_130.ckpt[0m
[[36m2023-07-14 09:02:52,106[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/0[0m
[[36m2023-07-14 09:02:52,119[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.10699297487735748>[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
`Trainer.fit` stopped: `max_epochs=400` reached.
Epoch 399/399 ━━━━━━━━━━━━━━━ 18/18 0:00:00 •       139.49it/s v_num: 0         
                                    0:00:00                    val/loss: 0.036  
                                                               val/mae: 0.119   
                                                               val/mae_best:    
                                                               0.103 train/loss:
                                                               0.018 train/mae: 
                                                               0.088            
[[36m2023-07-14 09:07:25,466[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/4/checkpoints/epoch_347.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/4/checkpoints/epoch_347.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test/loss         │   0.028712334111332893    │
│         test/mae          │    0.09791587293148041    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 264.43it/s 
[[36m2023-07-14 09:07:25,681[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/4/checkpoints/epoch_347.ckpt[0m
[[36m2023-07-14 09:07:25,682[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/train/multiruns/2023-07-14_08-34-29/4[0m
[[36m2023-07-14 09:07:25,689[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Retrieved metric value! <val/mae_best=0.1033167615532875>[0m
[[36m2023-07-14 09:07:25,704[0m][[35mHYDRA[0m] Best parameters: {'model.optimizer.lr': 0.05616349898795594, 'data.batch_size': 256}[0m
[[36m2023-07-14 09:07:25,705[0m][[35mHYDRA[0m] Best value: 0.0957183837890625[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
