The activation script must be sourced, otherwise the virtual environment will not work.
Setting vars
[[36m2023-07-18 07:18:43,573[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-18 07:18:43,581[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-18 07:18:43,581[0m][[34msrc.utils.rich_utils[0m][[33mWARNING[0m] - Field 'callbacks' not found in config. Skipping 'callbacks' config printing...[0m
[[36m2023-07-18 07:18:43,581[0m][[34msrc.utils.rich_utils[0m][[33mWARNING[0m] - Field 'logger' not found in config. Skipping 'logger' config printing...[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.stars_datamodule.StarsDataModule                     
â”‚       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
â”‚       batch_size: 64                                                          
â”‚       train_val_test_split:                                                   
â”‚       - 0.7                                                                   
â”‚       - 0.1                                                                   
â”‚       - 0.2                                                                   
â”‚       num_workers: 0                                                          
â”‚       pin_memory: false                                                       
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.stars_module.StarsLitModule                        
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0                                                     
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
â”‚         _partial_: true                                                       
â”‚         mode: min                                                             
â”‚         factor: 0.5                                                           
â”‚         patience: 10                                                          
â”‚       net:                                                                    
â”‚         _target_: src.models.components.multilayer_perceptron.MLP             
â”‚         input_size: 4302                                                      
â”‚         lin1_size: 2048                                                       
â”‚         lin2_size: 1024                                                       
â”‚         lin3_size: 512                                                        
â”‚         lin4_size: 256                                                        
â”‚         lin5_size: 64                                                         
â”‚         lin6_size: 32                                                         
â”‚         output_size: 5                                                        
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/
â”‚       min_epochs: 1                                                           
â”‚       max_epochs: 10                                                          
â”‚       accelerator: cpu                                                        
â”‚       devices: 1                                                              
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
â”‚       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
â”‚       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
â”‚       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/runs/2
â”‚       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ eval                                                                    
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                 
â””â”€â”€ ckpt_path
    â””â”€â”€ /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-17_1
[[36m2023-07-18 07:18:43,621[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-18 07:18:45,462[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-18 07:18:45,636[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-18 07:18:45,637[0m][[34msrc.utils.instantiators[0m][[33mWARNING[0m] - No logger configs found! Skipping...[0m
[[36m2023-07-18 07:18:45,637[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-18 07:18:46,426[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=4)`.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-17_14-34-42/checkpoints/epoch_228.ckpt
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-17_14-34-42/checkpoints/epoch_228.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting: 0it [00:00, ?it/s]Predicting:   0%|          | 0/53 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/53 [00:00<?, ?it/s]Predicting DataLoader 0:   2%|â–         | 1/53 [00:00<00:01, 26.24it/s]Predicting DataLoader 0:   4%|â–         | 2/53 [00:00<00:01, 43.64it/s]Predicting DataLoader 0:   6%|â–Œ         | 3/53 [00:00<00:00, 55.73it/s]Predicting DataLoader 0:   8%|â–Š         | 4/53 [00:00<00:00, 65.72it/s]Predicting DataLoader 0:   9%|â–‰         | 5/53 [00:00<00:00, 73.60it/s]Predicting DataLoader 0:  11%|â–ˆâ–        | 6/53 [00:00<00:00, 80.23it/s]Predicting DataLoader 0:  13%|â–ˆâ–Ž        | 7/53 [00:00<00:00, 85.76it/s]Predicting DataLoader 0:  15%|â–ˆâ–Œ        | 8/53 [00:00<00:00, 90.31it/s]Predicting DataLoader 0:  17%|â–ˆâ–‹        | 9/53 [00:00<00:00, 94.42it/s]Predicting DataLoader 0:  19%|â–ˆâ–‰        | 10/53 [00:00<00:00, 97.91it/s]Predicting DataLoader 0:  21%|â–ˆâ–ˆ        | 11/53 [00:00<00:00, 101.00it/s]Predicting DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 12/53 [00:00<00:00, 68.07it/s] Predicting DataLoader 0:  25%|â–ˆâ–ˆâ–       | 13/53 [00:00<00:00, 59.61it/s]Predicting DataLoader 0:  26%|â–ˆâ–ˆâ–‹       | 14/53 [00:00<00:00, 62.29it/s]Predicting DataLoader 0:  28%|â–ˆâ–ˆâ–Š       | 15/53 [00:00<00:00, 64.76it/s]Predicting DataLoader 0:  30%|â–ˆâ–ˆâ–ˆ       | 16/53 [00:00<00:00, 67.16it/s]Predicting DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 17/53 [00:00<00:00, 69.43it/s]Predicting DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 18/53 [00:00<00:00, 71.59it/s]Predicting DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/53 [00:00<00:00, 73.66it/s]Predicting DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 20/53 [00:00<00:00, 75.59it/s]Predicting DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 21/53 [00:00<00:00, 77.45it/s]Predicting DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/53 [00:00<00:00, 79.23it/s]Predicting DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 23/53 [00:00<00:00, 80.91it/s]Predicting DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 24/53 [00:00<00:00, 82.49it/s]Predicting DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/53 [00:00<00:00, 84.03it/s]Predicting DataLoader 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 26/53 [00:00<00:00, 85.45it/s]Predicting DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/53 [00:00<00:00, 86.87it/s]Predicting DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 28/53 [00:00<00:00, 88.22it/s]Predicting DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/53 [00:00<00:00, 89.54it/s]Predicting DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 30/53 [00:00<00:00, 90.74it/s]Predicting DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 31/53 [00:00<00:00, 91.85it/s]Predicting DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 32/53 [00:00<00:00, 92.99it/s]Predicting DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 33/53 [00:00<00:00, 94.10it/s]Predicting DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/53 [00:00<00:00, 95.16it/s]Predicting DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 35/53 [00:00<00:00, 96.19it/s]Predicting DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 36/53 [00:00<00:00, 97.16it/s]Predicting DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 37/53 [00:00<00:00, 98.11it/s]Predicting DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 38/53 [00:00<00:00, 99.05it/s]Predicting DataLoader 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 39/53 [00:00<00:00, 99.94it/s]Predicting DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 40/53 [00:00<00:00, 100.83it/s]Predicting DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 41/53 [00:00<00:00, 101.64it/s]Predicting DataLoader 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 42/53 [00:00<00:00, 102.45it/s]Predicting DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 43/53 [00:00<00:00, 103.21it/s]Predicting DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 44/53 [00:00<00:00, 103.94it/s]Predicting DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/53 [00:00<00:00, 104.63it/s]Predicting DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 46/53 [00:00<00:00, 105.32it/s]Predicting DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 47/53 [00:00<00:00, 105.91it/s]Predicting DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 48/53 [00:00<00:00, 106.56it/s]Predicting DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 49/53 [00:00<00:00, 107.22it/s]Predicting DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/53 [00:00<00:00, 107.83it/s]Predicting DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 51/53 [00:00<00:00, 108.45it/s]Predicting DataLoader 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 52/53 [00:00<00:00, 109.06it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:00<00:00, 110.02it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:00<00:00, 109.96it/s]
[[36m2023-07-18 07:19:12,350[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/runs/2023-07-18_07-18-43[0m
