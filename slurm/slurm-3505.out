The activation script must be sourced, otherwise the virtual environment will not work.
Setting vars
[[36m2023-07-14 11:50:55,946[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2023-07-14 11:50:55,953[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
[[36m2023-07-14 11:50:55,953[0m][[34msrc.utils.rich_utils[0m][[33mWARNING[0m] - Field 'callbacks' not found in config. Skipping 'callbacks' config printing...[0m
[[36m2023-07-14 11:50:55,954[0m][[34msrc.utils.rich_utils[0m][[33mWARNING[0m] - Field 'logger' not found in config. Skipping 'logger' config printing...[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.stars_datamodule.StarsDataModule                     
â”‚       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
â”‚       batch_size: 64                                                          
â”‚       train_val_test_split:                                                   
â”‚       - 0.7                                                                   
â”‚       - 0.1                                                                   
â”‚       - 0.2                                                                   
â”‚       num_workers: 0                                                          
â”‚       pin_memory: false                                                       
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.stars_module.StarsLitModule                        
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0                                                     
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
â”‚         _partial_: true                                                       
â”‚         mode: min                                                             
â”‚         factor: 0.5                                                           
â”‚         patience: 10                                                          
â”‚       net:                                                                    
â”‚         _target_: src.models.components.multilayer_perceptron.MLP             
â”‚         input_size: 4302                                                      
â”‚         lin1_size: 2048                                                       
â”‚         lin2_size: 1024                                                       
â”‚         lin3_size: 512                                                        
â”‚         lin4_size: 256                                                        
â”‚         lin5_size: 64                                                         
â”‚         lin6_size: 32                                                         
â”‚         output_size: 4                                                        
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/
â”‚       min_epochs: 1                                                           
â”‚       max_epochs: 10                                                          
â”‚       accelerator: cpu                                                        
â”‚       devices: 1                                                              
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /p/haicluster/niesel1/lightning-hydra-stars                   
â”‚       data_dir: /p/haicluster/niesel1/lightning-hydra-stars/data/             
â”‚       log_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/              
â”‚       output_dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/runs/2
â”‚       work_dir: /p/haicluster/niesel1/lightning-hydra-stars/src               
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ eval                                                                    
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                 
â””â”€â”€ ckpt_path
    â””â”€â”€ /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-14_1
[[36m2023-07-14 11:50:55,994[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.stars_datamodule.StarsDataModule>[0m
[[36m2023-07-14 11:50:58,267[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.stars_module.StarsLitModule>[0m
[[36m2023-07-14 11:50:58,434[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2023-07-14 11:50:58,435[0m][[34msrc.utils.instantiators[0m][[33mWARNING[0m] - No logger configs found! Skipping...[0m
[[36m2023-07-14 11:50:58,435[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
  rank_zero_warn(
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2023-07-14 11:50:59,344[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
Restoring states from the checkpoint path at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-14_10-12-31/checkpoints/epoch_293.ckpt
Loaded model weights from the checkpoint at /p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-14_10-12-31/checkpoints/epoch_293.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
[[36m2023-07-14 11:51:09,667[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/p/haicluster/niesel1/lightning-hydra-stars/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "eval.py", line 76, in evaluate
    predictions = trainer.predict(model=model, datamodule=datamodule, ckpt_path=cfg.ckpt_path)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 843, in predict
    return call._call_and_handle_interrupt(
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 885, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run_stage
    return self.predict_loop.run()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/prediction_loop.py", line 101, in run
    self.setup_data()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/prediction_loop.py", line 127, in setup_data
    dataloaders = _request_dataloader(source)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 330, in _request_dataloader
    return data_source.dataloader()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 300, in dataloader
    return call._call_lightning_datamodule_hook(self.instance.trainer, self.name)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 164, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/core/hooks.py", line 491, in predict_dataloader
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: `predict_dataloader` must be implemented to be used with the Lightning Trainer
[[36m2023-07-14 11:51:09,693[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /p/haicluster/niesel1/lightning-hydra-stars/logs/eval/runs/2023-07-14_11-50-55[0m
Error executing job with overrides: ['ckpt_path=/p/haicluster/niesel1/lightning-hydra-stars/logs/train/runs/2023-07-14_10-12-31/checkpoints/epoch_293.ckpt']
Traceback (most recent call last):
  File "eval.py", line 89, in main
    evaluate(cfg)
  File "/p/haicluster/niesel1/lightning-hydra-stars/src/utils/utils.py", line 75, in wrap
    raise ex
  File "/p/haicluster/niesel1/lightning-hydra-stars/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "eval.py", line 76, in evaluate
    predictions = trainer.predict(model=model, datamodule=datamodule, ckpt_path=cfg.ckpt_path)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 843, in predict
    return call._call_and_handle_interrupt(
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 885, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run_stage
    return self.predict_loop.run()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/prediction_loop.py", line 101, in run
    self.setup_data()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/loops/prediction_loop.py", line 127, in setup_data
    dataloaders = _request_dataloader(source)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 330, in _request_dataloader
    return data_source.dataloader()
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 300, in dataloader
    return call._call_lightning_datamodule_hook(self.instance.trainer, self.name)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 164, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/p/haicluster/niesel1/venv_stars/venv/lib/python3.8/site-packages/lightning/pytorch/core/hooks.py", line 491, in predict_dataloader
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: `predict_dataloader` must be implemented to be used with the Lightning Trainer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
srun: error: haicluster1: task 0: Exited with exit code 1
